{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolated Rotary Positional Embedding and Helper Functions\n",
    "class InterpolatedRotaryEmbedding(nn.Module):\n",
    "    \"\"\"Implements Interpolated Rotary Positional Embedding (RoPE) with interpolation for longer sequences.\"\"\"\n",
    "    def __init__(self, dim, max_seq_len, original_seq_len):\n",
    "        super().__init__()\n",
    "        self.original_seq_len = original_seq_len\n",
    "        self.max_seq_len = max_seq_len\n",
    "        # Interpolated RoPE scales down the frequencies for longer sequences\n",
    "        # This allows the model to handle sequences longer than the original training sequences\n",
    "        self.scale = original_seq_len / max_seq_len\n",
    "        \n",
    "        # Original frequency computation as in standard RoPE\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "    \n",
    "    def forward(self, seq_len, device):\n",
    "        \"\"\"\n",
    "        Generates interpolated sinusoidal embeddings for Interpolated RoPE.\n",
    "\n",
    "        Args:\n",
    "            seq_len (int): The length of the sequence.\n",
    "            device (torch.device): The device to create tensors on.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Sinusoidal embeddings of shape (seq_len, dim).\n",
    "        \"\"\"\n",
    "        # In Interpolated RoPE, frequencies are scaled\n",
    "        # This scaling allows the embeddings to adapt to different sequence lengths\n",
    "        scaled_freq = self.inv_freq * self.scale\n",
    "\n",
    "        # Generate positions (no scaling needed here, same as in standard RoPE)\n",
    "        t = torch.arange(seq_len, device=device).type_as(scaled_freq)\n",
    "        \n",
    "        # Apply scaled frequencies to positions (outer product)\n",
    "        freqs = torch.einsum('i , j -> i j', t, scaled_freq)\n",
    "        \n",
    "        # Combine sin and cos embeddings\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        return emb  # (seq_len, dim)\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"Helper function for rotating half of the dimensions\"\"\"\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, sinusoidal_pos):\n",
    "    \"\"\"\n",
    "    Applies RoPE to query and key tensors.\n",
    "\n",
    "    Args:\n",
    "        q (torch.Tensor): Query tensor of shape (batch_size, num_heads, seq_len, head_dim).\n",
    "        k (torch.Tensor): Key tensor of shape (batch_size, num_heads, seq_len, head_dim).\n",
    "        sinusoidal_pos (torch.Tensor): Sinusoidal embeddings of shape (seq_len, head_dim).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Rotated query and key tensors.\n",
    "    \"\"\"\n",
    "    sin, cos = sinusoidal_pos.sin(), sinusoidal_pos.cos()\n",
    "    sin = sin.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, seq_len, head_dim)\n",
    "    cos = cos.unsqueeze(0).unsqueeze(0)\n",
    "    q_rot = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_rot = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_rot, k_rot\n",
    "\n",
    "# Neural network components\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    \"\"\"Simple feed-forward network to project input features\"\"\"\n",
    "    def __init__(self, d_in, d_model):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Linear(d_in, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head self-attention mechanism with Interpolated RoPE\"\"\"\n",
    "    def __init__(self, d_model, num_heads, max_seq_len, original_seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.qkv_proj = nn.Linear(d_model, 3 * d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Use Interpolated Rotary Embedding\n",
    "        self.rotary_emb = InterpolatedRotaryEmbedding(self.head_dim, max_seq_len, original_seq_len)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the multi-head attention with Interpolated RoPE.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (seq_len, batch_size, d_model).\n",
    "            key_padding_mask (torch.Tensor, optional): Padding mask of shape (batch_size, seq_len).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (seq_len, batch_size, d_model).\n",
    "        \"\"\"\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "\n",
    "        # Project to query, key, value\n",
    "        qkv = self.qkv_proj(x)  # Shape: (seq_len, batch_size, 3*d_model)\n",
    "        qkv = qkv.view(seq_len, batch_size, 3, self.num_heads, self.head_dim)\n",
    "        qkv = qkv.permute(2, 1, 3, 0, 4)  # Shape: (3, batch_size, num_heads, seq_len, head_dim)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # Each shape: (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "        # Generate sinusoidal positional embeddings\n",
    "        sinusoidal_pos = self.rotary_emb(seq_len, device=x.device)  # Shape: (seq_len, head_dim)\n",
    "\n",
    "        # Apply Interpolated RoPE to q and k\n",
    "        q, k = apply_rotary_pos_emb(q, k, sinusoidal_pos)\n",
    "\n",
    "        # Compute scaled dot-product attention\n",
    "        attn_scores = torch.einsum('bnqd, bnkd -> bnqk', q, k)  # Shape: (batch_size, num_heads, seq_len, seq_len)\n",
    "        attn_scores = attn_scores / (self.head_dim ** 0.5)\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            # key_padding_mask: (batch_size, seq_len)\n",
    "            attn_scores = attn_scores.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf'))\n",
    "\n",
    "        attn_probs = F.softmax(attn_scores, dim=-1)  # Shape: (batch_size, num_heads, seq_len, seq_len)\n",
    "\n",
    "        attn_output = torch.einsum('bnqk, bnkd -> bnqd', attn_probs, v)  # Shape: (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "        # Concatenate heads\n",
    "        attn_output = attn_output.permute(2, 0, 1, 3).contiguous()  # Shape: (seq_len, batch_size, num_heads, head_dim)\n",
    "        attn_output = attn_output.view(seq_len, batch_size, self.d_model)  # Shape: (seq_len, batch_size, d_model)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.out_proj(attn_output)  # Shape: (seq_len, batch_size, d_model)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Transformer encoder layer with self-attention and feed-forward network\"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, max_seq_len, original_seq_len):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads, max_seq_len, original_seq_len)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (seq_len, batch_size, d_model).\n",
    "            src_key_padding_mask (torch.Tensor, optional): Padding mask.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of the same shape as input.\n",
    "        \"\"\"\n",
    "        # Multi-head attention with residual connection and layer normalization\n",
    "        attn_output = self.mha(x, key_padding_mask=src_key_padding_mask)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        # Feed-forward network with residual connection and layer normalization\n",
    "        ff_output = self.ff(x)\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Stack of transformer encoder layers\"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, max_seq_len, original_seq_len):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, max_seq_len, original_seq_len) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Passes the input through the stack of encoder layers.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (seq_len, batch_size, d_model).\n",
    "            src_key_padding_mask (torch.Tensor, optional): Padding mask.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (seq_len, batch_size, d_model).\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_key_padding_mask)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Simple linear decoder to project back to output dimension\"\"\"\n",
    "    def __init__(self, d_model, d_out):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Projects the encoder output to the desired output dimension.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (seq_len, batch_size, d_model).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (seq_len, batch_size, d_out).\n",
    "        \"\"\"\n",
    "        return self.linear(x)\n",
    "\n",
    "class Astromer(nn.Module):\n",
    "    \"\"\"Main model architecture for light curve processing\"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, max_seq_len, original_seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.fnn = FeedForwardNetwork(1, d_model)\n",
    "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, max_seq_len, original_seq_len)\n",
    "        self.decoder = Decoder(d_model, 1)\n",
    "\n",
    "    def forward(self, times, magnitudes, lengths, mask_prob=0.15):\n",
    "        \"\"\"\n",
    "        Processes the input light curves and reconstructs the magnitudes.\n",
    "\n",
    "        Args:\n",
    "            times (torch.Tensor): Time steps tensor of shape (batch_size, seq_len).\n",
    "            magnitudes (torch.Tensor): Magnitudes tensor of shape (batch_size, seq_len).\n",
    "            lengths (torch.Tensor): Actual lengths of each sequence in the batch.\n",
    "            mask_prob (float): Probability of masking an input magnitude.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed magnitudes of shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = magnitudes.size()\n",
    "\n",
    "        # Normalize time steps\n",
    "        times = self.normalize_times(times, lengths)\n",
    "\n",
    "        # Apply masking and initial feature projection\n",
    "        masked_magnitudes = self.mask_magnitudes(magnitudes, lengths, mask_prob)\n",
    "        x = self.fnn(masked_magnitudes.unsqueeze(-1))  # Shape: (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Prepare input for transformer: transpose to (seq_len, batch_size, d_model)\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        # Create attention padding mask\n",
    "        padding_mask = self.create_padding_mask(lengths, seq_len)  # Shape: (batch_size, seq_len)\n",
    "\n",
    "        # Process through encoder\n",
    "        encoded = self.encoder(x, src_key_padding_mask=padding_mask)\n",
    "\n",
    "        # Decode to final predictions\n",
    "        decoded = self.decoder(encoded)  # Shape: (seq_len, batch_size, 1)\n",
    "        reconstructed = decoded.squeeze(-1).transpose(0, 1)  # Shape: (batch_size, seq_len)\n",
    "\n",
    "        return reconstructed\n",
    "\n",
    "    def normalize_times(self, times, lengths):\n",
    "        \"\"\"\n",
    "        Normalizes time steps within each sequence to the range [0, 1].\n",
    "\n",
    "        Args:\n",
    "            times (torch.Tensor): Time steps tensor of shape (batch_size, seq_len).\n",
    "            lengths (torch.Tensor): Actual lengths of each sequence.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Normalized time steps tensor.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = times.size()\n",
    "        times_normalized = times.clone()\n",
    "        for i in range(batch_size):\n",
    "            length = lengths[i]\n",
    "            seq_times = times[i, :length]\n",
    "            min_t = seq_times.min()\n",
    "            max_t = seq_times.max()\n",
    "            if max_t > min_t:\n",
    "                times_normalized[i, :length] = (seq_times - min_t) / (max_t - min_t)\n",
    "            else:\n",
    "                times_normalized[i, :length] = 0.0  # All times are the same\n",
    "        return times_normalized\n",
    "\n",
    "    def mask_magnitudes(self, magnitudes, lengths, mask_prob):\n",
    "        \"\"\"\n",
    "        Randomly masks input magnitudes for denoising training.\n",
    "\n",
    "        Args:\n",
    "            magnitudes (torch.Tensor): Magnitudes tensor of shape (batch_size, seq_len).\n",
    "            lengths (torch.Tensor): Actual lengths of each sequence.\n",
    "            mask_prob (float): Probability of masking an input magnitude.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Masked magnitudes tensor.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = magnitudes.size()\n",
    "        # Create a mask for valid positions\n",
    "        valid_mask = torch.arange(seq_len, device=lengths.device).unsqueeze(0) < lengths.unsqueeze(1)\n",
    "        # Create random mask for masking magnitudes\n",
    "        random_mask = (torch.rand(batch_size, seq_len, device=magnitudes.device) < mask_prob) & valid_mask\n",
    "        masked_magnitudes = magnitudes.clone()\n",
    "        masked_magnitudes[random_mask] = 0.0\n",
    "        return masked_magnitudes\n",
    "\n",
    "    def create_padding_mask(self, lengths, max_length):\n",
    "        \"\"\"\n",
    "        Creates mask for padding tokens in attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            lengths (torch.Tensor): Actual lengths of each sequence.\n",
    "            max_length (int): Maximum sequence length in the batch.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Padding mask of shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        # Mask positions that are padding (True for padding positions)\n",
    "        padding_mask = torch.arange(max_length, device=lengths.device).unsqueeze(0) >= lengths.unsqueeze(1)\n",
    "        return padding_mask  # Shape: (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class setup\n",
    "class LightCurveDataset(Dataset):\n",
    "    \"\"\"Dataset class for light curve data with padding\"\"\"\n",
    "    def __init__(self, times, magnitudes, max_length):\n",
    "        self.times = times\n",
    "        self.magnitudes = magnitudes\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.times)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        time = self.times[idx]\n",
    "        magnitude = self.magnitudes[idx]\n",
    "        length = len(time)\n",
    "\n",
    "        # Pad sequences to max_length\n",
    "        padded_time = torch.zeros(self.max_length)\n",
    "        padded_magnitude = torch.zeros(self.max_length)\n",
    "        \n",
    "        padded_time[:length] = torch.tensor(time, dtype=torch.float32)\n",
    "        padded_magnitude[:length] = torch.tensor(magnitude, dtype=torch.float32)\n",
    "        \n",
    "        return padded_time, padded_magnitude, length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "d_ff = 256\n",
    "num_layers = 3\n",
    "max_seq_len = 100\n",
    "original_seq_len = 50\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = Astromer(\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    d_ff=d_ff,\n",
    "    num_layers=num_layers,\n",
    "    max_seq_len=max_seq_len,\n",
    "    original_seq_len=original_seq_len\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Astromer(\n",
       "  (fnn): FeedForwardNetwork(\n",
       "    (mlp): Linear(in_features=1, out_features=128, bias=True)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (mha): MultiHeadAttention(\n",
       "          (qkv_proj): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (rotary_emb): InterpolatedRotaryEmbedding()\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "file_path = '../Data/synthetic_light_curves.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert all odd sample_ids to sample_id - 1\n",
    "df['sample_id'] = df['sample_id'].apply(lambda x: x - 1 if x % 2 != 0 else x)\n",
    "\n",
    "grouped = df.groupby('sample_id')\n",
    "\n",
    "# Extract time series data\n",
    "times = [group['time_mjd'].values for _, group in grouped]\n",
    "magnitudes = [group['magnitude'].values for _, group in grouped]\n",
    "max_length = max(len(t) for t in times)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_times, test_times, train_mags, test_mags = train_test_split(\n",
    "    times, magnitudes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = LightCurveDataset(train_times, train_mags, max_length)\n",
    "test_dataset = LightCurveDataset(test_times, test_mags, max_length)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, optimizer, train_loader, test_loader, num_epochs=10):\n",
    "    \"\"\"Training loop with validation\"\"\"\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    best_test_loss = float('inf')\n",
    "    model_dir = '../Models'\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    best_model_path = os.path.join(model_dir, 'interpolated-rope-astromer.pth')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for times, magnitudes, lengths in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = model(times, magnitudes, lengths)\n",
    "            loss = criterion(reconstructed, magnitudes)\n",
    "            # Apply mask to compute loss only on valid timesteps\n",
    "            mask = torch.arange(magnitudes.size(1)).expand(magnitudes.size(0), magnitudes.size(1)) < lengths.unsqueeze(1)\n",
    "            loss = (loss * mask.float()).sum() / mask.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for times, magnitudes, lengths in test_loader:\n",
    "                reconstructed = model(times, magnitudes, lengths)\n",
    "                loss = criterion(reconstructed, magnitudes)\n",
    "                mask = torch.arange(magnitudes.size(1)).expand(magnitudes.size(0), magnitudes.size(1)) < lengths.unsqueeze(1)\n",
    "                loss = (loss * mask.float()).sum() / mask.sum()\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"New best model saved to {best_model_path}\")\n",
    "    \n",
    "    print(f\"Training completed. Best model saved with test loss: {best_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.0515, Test Loss: 0.0535\n",
      "New best model saved to ../Models/interpolated-rope-astromer.pth\n",
      "Epoch 2/10, Train Loss: 0.0504, Test Loss: 0.0512\n",
      "New best model saved to ../Models/interpolated-rope-astromer.pth\n",
      "Epoch 3/10, Train Loss: 0.0497, Test Loss: 0.0470\n",
      "New best model saved to ../Models/interpolated-rope-astromer.pth\n",
      "Epoch 4/10, Train Loss: 0.0485, Test Loss: 0.0484\n",
      "Epoch 5/10, Train Loss: 0.0480, Test Loss: 0.0470\n",
      "New best model saved to ../Models/interpolated-rope-astromer.pth\n",
      "Epoch 6/10, Train Loss: 0.0480, Test Loss: 0.0435\n",
      "New best model saved to ../Models/interpolated-rope-astromer.pth\n",
      "Epoch 7/10, Train Loss: 0.0475, Test Loss: 0.0414\n",
      "New best model saved to ../Models/interpolated-rope-astromer.pth\n",
      "Epoch 8/10, Train Loss: 0.0455, Test Loss: 0.0443\n",
      "Epoch 9/10, Train Loss: 0.0447, Test Loss: 0.0495\n",
      "Epoch 10/10, Train Loss: 0.0452, Test Loss: 0.0445\n",
      "Training completed. Best model saved with test loss: 0.0414\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train(model, optimizer, train_loader, test_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time per sample: 59.30 ms\n",
      "95.0% CI: [8.55, 66.00] ms\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test inference time and plot distribution\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_inference_time(model, test_loader, num_runs=100, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Measure the average inference time per sample for a given model and plot the distribution of times.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model to test.\n",
    "        test_loader: DataLoader containing the test dataset.\n",
    "        num_runs (int): Number of inference runs to average over (default: 100).\n",
    "        confidence_level (float): Confidence level for interval calculation (default: 0.95).\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Get the device (CPU or GPU) that the model is on\n",
    "    device = next(model.parameters()).device\n",
    "    total_time = 0\n",
    "    total_samples = 0\n",
    "    all_times = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        for times, magnitudes, lengths in test_loader:\n",
    "            # Move input data to the same device as the model\n",
    "            times, magnitudes, lengths = times.to(device), magnitudes.to(device), lengths.to(device)\n",
    "            batch_size = times.size(0)\n",
    "            \n",
    "            # Perform a warm-up run to ensure GPU is ready\n",
    "            _ = model(times, magnitudes, lengths)\n",
    "            \n",
    "            # Timed runs\n",
    "            batch_times = []\n",
    "            for _ in range(num_runs):\n",
    "                start_time = time.time()\n",
    "                _ = model(times, magnitudes, lengths)\n",
    "                end_time = time.time()\n",
    "                batch_times.extend([end_time - start_time] * batch_size)\n",
    "            \n",
    "            all_times.extend(batch_times)\n",
    "            total_time += sum(batch_times)\n",
    "            total_samples += batch_size * num_runs\n",
    "    \n",
    "    # Calculate overall average inference time per sample\n",
    "    avg_inference_time = total_time / total_samples\n",
    "    \n",
    "    # Calculate confidence interval\n",
    "    alpha = 1 - confidence_level\n",
    "    times_array = np.array(all_times)\n",
    "    ci_lower = np.percentile(times_array, alpha * 100 / 2)\n",
    "    ci_upper = np.percentile(times_array, 100 - (alpha * 100 / 2))\n",
    "    \n",
    "    print(f\"Average inference time per sample: {avg_inference_time*1000:.2f} ms\")\n",
    "    print(f\"{confidence_level*100:.1f}% CI: [{ci_lower*1000:.2f}, {ci_upper*1000:.2f}] ms\")\n",
    "    \n",
    "    # Plot the distribution of inference times\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(times_array * 1000, bins=50, color='blue', alpha=0.7)\n",
    "    plt.title('Distribution of Inference Times per Sample')\n",
    "    plt.xlabel('Inference Time (ms)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Test inference time using the trained model and test data loader\n",
    "test_inference_time(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
